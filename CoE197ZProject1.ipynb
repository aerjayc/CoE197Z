{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fromm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aqW4K2fE2M9k"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeglEVvP0TUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "31dd7238-3b32-480d-d488-538fa81902d2"
      },
      "source": [
        "###Reyes, Marcus Group 7\n",
        "\n",
        "###CoE 197Z Project 1.1\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout,BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.optimizers import adam,sgd\n",
        "from keras import optimizers\n",
        "\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import string\n",
        "\n",
        "#from sixfunctions import load_train, load_x_test, clean_data_with_mean\n",
        "!pip install category_encoders"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqG88I49TdBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from importlib import reload\n",
        "import sixfunctions\n",
        "sixfunctions = reload(sixfunctions)\n",
        "from sixfunctions import load_train, load_x_test, preprocess_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phFfzI3u0ppG",
        "colab_type": "code",
        "outputId": "478fe879-dcfb-4635-cc50-f2e030cb0e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "train   = pd.read_csv(\"train_set_values.csv\")\n",
        "labels  = pd.read_csv(\"train_set_labels.csv\")\n",
        "test    = pd.read_csv(\"test_values.csv\")\n",
        "\n",
        "columns = set(train.columns)\n",
        "drop_cols = {'id', 'num_private',\n",
        "             'quality_group',   # exact duplicate of quality\n",
        "             'recorded_by'}     # uniform value\n",
        "unique_cols = { 'funder',       # 1898 unique values\n",
        "                'ward',         # 2092 unique values\n",
        "                'installer',    # 2146 unique values\n",
        "                'scheme_name',  # 2697 unique values\n",
        "                'subvillage',   # 19288 unique values\n",
        "                'wpt_name' }    # 37400 unique values\n",
        "binary_cols = {\"permit\", \"public_meeting\"}\n",
        "object_cols = set(train.select_dtypes(include=['object']).columns) - drop_cols\n",
        "onehot_cols = ((((object_cols | {'region_code', 'district_code'})\n",
        "                - {'date_recorded', 'permit', 'public_meeting'})\n",
        "                - unique_cols) - drop_cols)\n",
        "#print(f\"onehot_cols = {str(onehot_cols)}\")\n",
        "scale_cols = set(train.select_dtypes(include=['number']).columns)   \\\n",
        "                - onehot_cols - unique_cols - binary_cols - drop_cols | {\"year_recorded\"}\n",
        "\n",
        "train, labels = preprocess_data(train, labels, test, drop_cols,\n",
        "                                unique_cols, binary_cols, onehot_cols, scale_cols)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dropping: {'num_private', 'recorded_by', 'id', 'quality_group'}\n",
            "CLEANING  amount_tsh\n",
            "CLEANING  construction_year\n",
            "CLEANING  population\n",
            "cyclic encoding:\n",
            "\tdate_recorded -> (doy_recorded_sin, doy_recorded_cos)\n",
            "Normalization:\n",
            "\tconstruction_year [(1960.0, 2013.0)] -> [(-3.6574406124580006, 1.6079677259760634)]\n",
            "\tgps_height [(-90, 2770)] -> [(-1.0940495369292693, 3.0322765453176466)]\n",
            "\tamount_tsh [(0.2, 350000.0)] -> [(-0.3590986010964154, 117.97090065790498)]\n",
            "\tlatitude [(-11.64944018, -2e-08)] -> [(-2.0174538540773703, 1.9368783817775395)]\n",
            "\tpopulation [(1.0, 30500.0)] -> [(-0.6199883131902885, 66.89122175181514)]\n",
            "\tyear_recorded [(2002, 2013)] -> [(-10.348549589913485, 1.1247289744119464)]\n",
            "\tlongitude [(0.0, 40.34519307)] -> [(-5.188894889753043, 0.9543790152566973)]\n",
            "one-hot encoding:\n",
            "\tpayment:\t7 categories\n",
            "\tsource_type:\t7 categories\n",
            "\tquantity_group:\t5 categories\n",
            "\tregion:\t21 categories\n",
            "\tpayment_type:\t7 categories\n",
            "\twater_quality:\t8 categories\n",
            "\tbasin:\t9 categories\n",
            "\tsource_class:\t3 categories\n",
            "\tlga:\t125 categories\n",
            "\textraction_type:\t18 categories\n",
            "\tmanagement_group:\t5 categories\n",
            "\tquantity:\t5 categories\n",
            "\twaterpoint_type:\t7 categories\n",
            "\tmanagement:\t12 categories\n",
            "\twaterpoint_type_group:\t6 categories\n",
            "\tscheme_management:\t13 categories\n",
            "\textraction_type_class:\t7 categories\n",
            "\tsource:\t10 categories\n",
            "\tdistrict_code:\t20 categories\n",
            "\tregion_code:\t27 categories\n",
            "\textraction_type_group:\t13 categories\n",
            "BINARY ENCODING:\n",
            "\t subvillage \t 19288  unique values  -> 15  columns\n",
            "\t funder \t 1898  unique values  -> 11  columns\n",
            "\t installer \t 2146  unique values  -> 12  columns\n",
            "\t scheme_name \t 2697  unique values  -> 12  columns\n",
            "\t ward \t 2092  unique values  -> 12  columns\n",
            "\t wpt_name \t 37400  unique values  -> 16  columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vRRDSaJIic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train.to_numpy()\n",
        "y = labels.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqW4K2fE2M9k",
        "colab_type": "text"
      },
      "source": [
        "#### Old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e1kLX002LFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_not_include = {'quality_group',      # exact duplicate of 'quality'\n",
        "                  'recorded_by',        # uniform value\n",
        "\n",
        "                  'wpt_name',           #unique\n",
        "                  'subvillage',         #dup of loc, numerous\n",
        "                  'scheme_name',        #messy numerous\n",
        "                  'payment',            #duplicate of payment type\n",
        "                  'quantity_group',     #Dup of quantity\n",
        "                  'waterpoint_type_group',#dup of wtptype less data\n",
        "                  'source_type',        #dup of source\n",
        "                  'extraction_type',    #dup of extr_type_group\n",
        "                  #'extraction_type_group',\n",
        "                  'region'} - unique_cols#enc in regcode\n",
        "\n",
        "#These are sort of ordinal data\n",
        "do_not_one_hot = {'id','gps_height','doy_recorded_sin','doy_recorded_cos',\n",
        "                  'longitude','latitude','population','amount_tsh'} | unique_cols\n",
        "\n",
        "clean_up = {'population','amount_tsh'}\n",
        "\n",
        "#Tentatively do not include.\n",
        "do_not_include_tent = {'funder','installer','ward','lga'} - unique_cols\n",
        "\n",
        "#Don't know what it means \n",
        "do_not_include_temp = {'num_private'} - unique_cols\n",
        "\n",
        "\n",
        "x, train_col,y = load_train(\"train_set_values.csv\",\"train_set_labels.csv\",\n",
        "                            do_not_include, do_not_one_hot,\n",
        "                            clean_up, do_not_include_tent, do_not_include_temp,\n",
        "                            unique_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8vnqwhZ2O3M",
        "colab_type": "text"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xdZr_LgOZfY",
        "colab_type": "code",
        "outputId": "caf5e970-17da-4d81-8141-7578149120e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "###Model\n",
        "\n",
        "hidden = 1024\n",
        "dropout = 0.4\n",
        "\n",
        "(trash, input_dim) = x.shape\n",
        "\n",
        "activation = 'relu'\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(hidden, input_dim = input_dim))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation(activation))\n",
        "\n",
        "model.add(Dense(hidden, input_dim = input_dim))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation(activation))\n",
        "\n",
        "model.add(Dense(hidden, input_dim = input_dim))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation(activation))\n",
        "\n",
        "\n",
        "model.add(Dense(3,input_dim = hidden))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#history = model.fit(x, y, epochs=20, batch_size=4096*16, validation_split=0.2)\n",
        "history = model.fit(x, y, epochs=20, batch_size=256, validation_split=0.2)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47520 samples, validate on 11880 samples\n",
            "Epoch 1/20\n",
            "47520/47520 [==============================] - 6s 127us/step - loss: 0.6673 - acc: 0.7211 - val_loss: 0.5857 - val_acc: 0.7650\n",
            "Epoch 2/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.5702 - acc: 0.7644 - val_loss: 0.5509 - val_acc: 0.7770\n",
            "Epoch 3/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.5305 - acc: 0.7818 - val_loss: 0.5364 - val_acc: 0.7844\n",
            "Epoch 4/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.5028 - acc: 0.7931 - val_loss: 0.5272 - val_acc: 0.7851\n",
            "Epoch 5/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.4804 - acc: 0.8028 - val_loss: 0.5234 - val_acc: 0.7873\n",
            "Epoch 6/20\n",
            "47520/47520 [==============================] - 3s 68us/step - loss: 0.4592 - acc: 0.8106 - val_loss: 0.5177 - val_acc: 0.7928\n",
            "Epoch 7/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.4392 - acc: 0.8188 - val_loss: 0.5106 - val_acc: 0.7949\n",
            "Epoch 8/20\n",
            "47520/47520 [==============================] - 3s 68us/step - loss: 0.4224 - acc: 0.8252 - val_loss: 0.5198 - val_acc: 0.7943\n",
            "Epoch 9/20\n",
            "47520/47520 [==============================] - 3s 68us/step - loss: 0.4052 - acc: 0.8304 - val_loss: 0.5156 - val_acc: 0.7955\n",
            "Epoch 10/20\n",
            "47520/47520 [==============================] - 3s 69us/step - loss: 0.3913 - acc: 0.8390 - val_loss: 0.5254 - val_acc: 0.7928\n",
            "Epoch 11/20\n",
            "47520/47520 [==============================] - 3s 68us/step - loss: 0.3729 - acc: 0.8431 - val_loss: 0.5420 - val_acc: 0.7860\n",
            "Epoch 12/20\n",
            "47520/47520 [==============================] - 3s 67us/step - loss: 0.3620 - acc: 0.8489 - val_loss: 0.5306 - val_acc: 0.7913\n",
            "Epoch 13/20\n",
            "21760/47520 [============>.................] - ETA: 1s - loss: 0.3378 - acc: 0.8584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-6c561411f0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#history = model.fit(x, y, epochs=20, batch_size=4096*16, validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ2-AmxsWhSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d900d33-6bd2-467d-cca3-f9d1f50cac0e"
      },
      "source": [
        "\n",
        "max_score = -1\n",
        "iter_of_max = 0,0\n",
        "train_plot = []\n",
        "val_plot = []\n",
        "x_axis = []\n",
        "\n",
        "#Save the weights for k-fold validation\n",
        "model.save_weights('model.h5')\n",
        "\n",
        "amount = 120\n",
        "k_folds = 5\n",
        "\n",
        "###When i use k_folds instead of 10 for the np.zeros initialization it acts up\n",
        "val_plot = np.zeros((k_folds,amount))\n",
        "train_plot = np.zeros((k_folds,amount))\n",
        "test_plot = np.zeros((k_folds,amount)) \n",
        "x_axis = np.zeros((k_folds,amount))\n",
        "total = int(x.shape[0])\n",
        "for j in range(k_folds):\n",
        "\n",
        "    whole = np.arange(0,total)\n",
        "    test_range = np.arange((j)*(total/k_folds), (j)*(total/k_folds)+(total/k_folds),dtype = 'int')\n",
        "    \n",
        "    train_range = np.delete(whole, test_range)\n",
        "    \n",
        "    \n",
        "    #K-fold validation setup\n",
        "    x_train = x[train_range,:]\n",
        "    x_pretest = x[test_range,:]\n",
        "    y_train = y[train_range,:]\n",
        "    y_pretest = y[test_range,:]\n",
        "    \n",
        "    for i in range(amount):\n",
        "\n",
        "        history = model.fit(x_train, y_train, epochs = 1, batch_size = 4096*16, verbose = 0)\n",
        "        score = model.evaluate(x_pretest, y_pretest, batch_size = 512, verbose = 0)\n",
        "\n",
        "        if  float(100 * score[1]) > float(max_score):\n",
        "            max_score = float(100 * score[1])\n",
        "            iter_of_max = i,j\n",
        "        if i%10 == 0:\n",
        "            print(\"----------\",i,\"-\",j,\"-----------\")\n",
        "            print(\"Test accuracy: \", (100.0 * score[1]))\n",
        "            print(\"Maxscore: \", max_score, \"at\", iter_of_max,\"epoch-kthfold\")\n",
        "        \n",
        "        #for the plot\n",
        "        x_axis[j,i] = i\n",
        "        test_plot[j,i] = (score[1])\n",
        "        train_plot[j,i] = np.array(history.history['acc'])\n",
        "\n",
        "        \n",
        "\n",
        "    if j == k_folds - 1:\n",
        "        break\n",
        "    model.load_weights('model.h5')\n",
        "    print(\"Reloading Model\")\n",
        "    \n",
        "print(\"Done evaluating performance\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- 0 - 0 -----------\n",
            "Test accuracy:  54.23400671393783\n",
            "Maxscore:  54.23400671393783 at (0, 0) epoch-kthfold\n",
            "---------- 10 - 0 -----------\n",
            "Test accuracy:  67.4242424081873\n",
            "Maxscore:  67.74410774009397 at (9, 0) epoch-kthfold\n",
            "---------- 20 - 0 -----------\n",
            "Test accuracy:  71.74242421834155\n",
            "Maxscore:  71.74242421834155 at (20, 0) epoch-kthfold\n",
            "---------- 30 - 0 -----------\n",
            "Test accuracy:  73.41750840546707\n",
            "Maxscore:  73.80471382478271 at (28, 0) epoch-kthfold\n",
            "---------- 40 - 0 -----------\n",
            "Test accuracy:  75.06734007536762\n",
            "Maxscore:  75.06734007536762 at (40, 0) epoch-kthfold\n",
            "---------- 50 - 0 -----------\n",
            "Test accuracy:  75.90067340870095\n",
            "Maxscore:  75.90067340870095 at (50, 0) epoch-kthfold\n",
            "---------- 60 - 0 -----------\n",
            "Test accuracy:  76.82659933462689\n",
            "Maxscore:  76.95286196088952 at (59, 0) epoch-kthfold\n",
            "---------- 70 - 0 -----------\n",
            "Test accuracy:  77.66835018039151\n",
            "Maxscore:  77.66835018039151 at (70, 0) epoch-kthfold\n",
            "---------- 80 - 0 -----------\n",
            "Test accuracy:  77.76094274087386\n",
            "Maxscore:  77.76094274087386 at (80, 0) epoch-kthfold\n",
            "---------- 90 - 0 -----------\n",
            "Test accuracy:  77.97138049546317\n",
            "Maxscore:  77.99663302071568 at (86, 0) epoch-kthfold\n",
            "---------- 100 - 0 -----------\n",
            "Test accuracy:  77.3316498196085\n",
            "Maxscore:  78.19865319062563 at (97, 0) epoch-kthfold\n",
            "---------- 110 - 0 -----------\n",
            "Test accuracy:  78.1060605859917\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n",
            "Reloading Model\n",
            "---------- 0 - 1 -----------\n",
            "Test accuracy:  54.19191916783651\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n",
            "---------- 10 - 1 -----------\n",
            "Test accuracy:  68.49326599727978\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n",
            "---------- 20 - 1 -----------\n",
            "Test accuracy:  73.41750840948086\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n",
            "---------- 30 - 1 -----------\n",
            "Test accuracy:  74.88215486208598\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n",
            "---------- 40 - 1 -----------\n",
            "Test accuracy:  75.68181816174928\n",
            "Maxscore:  78.28282828282829 at (102, 0) epoch-kthfold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-b50c0257cb2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pretest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pretest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m  \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     def predict(self, x,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}