{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat-in-the-dat-j.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerjayc/CoE197Z/blob/master/cat_in_the_dat_j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJ2kjOs6mcA",
        "colab_type": "code",
        "outputId": "70673538-539b-4f3e-ad45-b2bc276dbb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout\n",
        "from keras.optimizers import adam\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction import FeatureHasher"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJmaJIE6LDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(props):\n",
        "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "    for col in props.columns:\n",
        "        if props[col].dtype != object:  # Exclude strings\n",
        "            \n",
        "            # Print current column type\n",
        "            \n",
        "            # make variables for Int, max and min\n",
        "            IsInt = False\n",
        "            mx = props[col].max()\n",
        "            mn = props[col].min()\n",
        "            \n",
        "            # Integer does not support NA, therefore, NA needs to be filled\n",
        "            if not np.isfinite(props[col]).all(): \n",
        "                NAlist.append(col)\n",
        "                props[col].fillna(mn-1,inplace=True)  \n",
        "                   \n",
        "            # test if column can be converted to an integer\n",
        "            asint = props[col].fillna(0).astype(np.int64)\n",
        "            result = (props[col] - asint)\n",
        "            result = result.sum()\n",
        "            if result > -0.01 and result < 0.01:\n",
        "                IsInt = True\n",
        "\n",
        "            \n",
        "            # Make Integer/unsigned Integer datatypes\n",
        "            if IsInt:\n",
        "                if mn >= 0:\n",
        "                    if mx < 255:\n",
        "                        props[col] = props[col].astype(np.uint8)\n",
        "                    elif mx < 65535:\n",
        "                        props[col] = props[col].astype(np.uint16)\n",
        "                    elif mx < 4294967295:\n",
        "                        props[col] = props[col].astype(np.uint32)\n",
        "                    else:\n",
        "                        props[col] = props[col].astype(np.uint64)\n",
        "                else:\n",
        "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                        props[col] = props[col].astype(np.int8)\n",
        "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                        props[col] = props[col].astype(np.int16)\n",
        "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                        props[col] = props[col].astype(np.int32)\n",
        "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                        props[col] = props[col].astype(np.int64)    \n",
        "            \n",
        "            # Make float datatypes 32 bit\n",
        "            else:\n",
        "                props[col] = props[col].astype(np.float32)\n",
        "            \n",
        "            # Print new column type\n",
        "    \n",
        "    # Print final result\n",
        "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "    return props, NAlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYXApa1-IPJ",
        "colab_type": "code",
        "outputId": "79711042-e8cf-4f98-f62c-caa1943b6234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/aerjayc/CoE197Z.git\n",
        "!cp CoE197Z/train.csv .\n",
        "!cp CoE197Z/test.csv .\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CoE197Z'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/35)\u001b[K\rremote: Counting objects:   5% (2/35)\u001b[K\rremote: Counting objects:   8% (3/35)\u001b[K\rremote: Counting objects:  11% (4/35)\u001b[K\rremote: Counting objects:  14% (5/35)\u001b[K\rremote: Counting objects:  17% (6/35)\u001b[K\rremote: Counting objects:  20% (7/35)\u001b[K\rremote: Counting objects:  22% (8/35)\u001b[K\rremote: Counting objects:  25% (9/35)\u001b[K\rremote: Counting objects:  28% (10/35)\u001b[K\rremote: Counting objects:  31% (11/35)\u001b[K\rremote: Counting objects:  34% (12/35)\u001b[K\rremote: Counting objects:  37% (13/35)\u001b[K\rremote: Counting objects:  40% (14/35)\u001b[K\rremote: Counting objects:  42% (15/35)\u001b[K\rremote: Counting objects:  45% (16/35)\u001b[K\rremote: Counting objects:  48% (17/35)\u001b[K\rremote: Counting objects:  51% (18/35)\u001b[K\rremote: Counting objects:  54% (19/35)\u001b[K\rremote: Counting objects:  57% (20/35)\u001b[K\rremote: Counting objects:  60% (21/35)\u001b[K\rremote: Counting objects:  62% (22/35)\u001b[K\rremote: Counting objects:  65% (23/35)\u001b[K\rremote: Counting objects:  68% (24/35)\u001b[K\rremote: Counting objects:  71% (25/35)\u001b[K\rremote: Counting objects:  74% (26/35)\u001b[K\rremote: Counting objects:  77% (27/35)\u001b[K\rremote: Counting objects:  80% (28/35)\u001b[K\rremote: Counting objects:  82% (29/35)\u001b[K\rremote: Counting objects:  85% (30/35)\u001b[K\rremote: Counting objects:  88% (31/35)\u001b[K\rremote: Counting objects:  91% (32/35)\u001b[K\rremote: Counting objects:  94% (33/35)\u001b[K\rremote: Counting objects:  97% (34/35)\u001b[K\rremote: Counting objects: 100% (35/35)\u001b[K\rremote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 35 (delta 12), reused 12 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "CoE197Z  sample_data  test.csv\ttrain.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlt5zY8F7OzE",
        "colab_type": "text"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LY02ikh-DJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "h = FeatureHasher(n_features = 200, input_type = \"string\")\n",
        "\n",
        "#Initialize nom_np\n",
        "data['nom_9'] = data['nom_9'].astype('str')\n",
        "nom_np = (h.transform(data['nom_9'].values)).todense()\n",
        "\n",
        "drop = ['id','nom_9']\n",
        "data = data.drop(columns = drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwx0yyHU_G47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Categorical to one_hot\n",
        "one_hot = ['bin_3', 'bin_4','nom_0','nom_1','nom_2','nom_3','nom_4','ord_1', 'ord_2', 'ord_3', 'ord_4','ord_5','day','month', 'nom_5','nom_6','nom_7', 'nom_8']\n",
        "for i,w in enumerate(one_hot):\n",
        "    data = pd.get_dummies(data, columns=[w], prefix = [w])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkP0Qq2n_rpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicate = ['bin_0','bin_1','bin_2','bin_3_F','bin_3_T','bin_4_Y','bin_4_N']\n",
        "duplicatecount = 2\n",
        "for i,w in enumerate(duplicate):\n",
        "    for j in range(duplicatecount):\n",
        "        data = pd.concat([data, data[w]],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsgQ9diq6p0p",
        "colab_type": "code",
        "outputId": "a8a347c9-c5b4-4f03-db10-2ef133e2c661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Categorical to labelled\n",
        "labelled = ['nom_7', 'nom_8']\n",
        "\n",
        "\n",
        "y_train = data['target'].to_numpy()\n",
        "y_train = keras.utils.to_categorical(y_train, 2)\n",
        "data = data.drop(columns = ['target'])\n",
        "\n",
        "\n",
        "columns_list = data.columns\n",
        "x = data.to_numpy()\n",
        "\n",
        "print(nom_np.shape,\"NOM_NP_SHAP\")\n",
        "print(x.shape)\n",
        "x = np.concatenate((x,nom_np), axis = 1)\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    del data, nom_np\n",
        "    print(\"cleared memory\")\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300000, 200) NOM_NP_SHAP\n",
            "(300000, 4496)\n",
            "(300000, 4696)\n",
            "cleared memory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJdVLl-KESgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Normalize data to large to be one-hot-encoded\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x = min_max_scaler.fit_transform(x)\n",
        "\n",
        "x_train = x[:300000,:]\n",
        "x_pretest = x[240000:,:]\n",
        "\n",
        "y_pretest = y_train[240000:,:]\n",
        "y_train = y_train[:300000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpGs8clr7S4f",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73iEIRMu6wi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af5c2ff0-8efc-4e35-d860-e50a33e36f31"
      },
      "source": [
        "hidden = 1024-128\n",
        "dropout = 0.55\n",
        "\n",
        "(trash, input_dim) = x.shape\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(hidden, input_dim = input_dim))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation('tanh'))\n",
        "\n",
        "model.add(Dense(hidden,input_dim = hidden))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation('tanh'))\n",
        "\n",
        "model.add(Dense(hidden,input_dim = hidden))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Activation('tanh'))\n",
        "\n",
        "model.add(Dense(2,input_dim = hidden))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "###To keep track of validation error\n",
        "\n",
        "for i in range(6):\n",
        "    model.fit(x_train, y_train, epochs = 1, batch_size = 4096*4)\n",
        "\n",
        "    score = model.evaluate(x_pretest, y_pretest, batch_size = 512)\n",
        "\n",
        "    print(\"\\nTest accuacy: %.4f%%\" % (100.0 * score[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 896)               4208512   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 896)               803712    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 896)               803712    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 1794      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 5,817,730\n",
            "Trainable params: 5,817,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 14s 48us/step - loss: 0.6856 - acc: 0.6467\n",
            "60000/60000 [==============================] - 2s 27us/step\n",
            "\n",
            "Test accuacy: 73.2983%\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 10s 32us/step - loss: 0.5156 - acc: 0.7451\n",
            "60000/60000 [==============================] - 2s 27us/step\n",
            "\n",
            "Test accuacy: 76.8950%\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 10s 32us/step - loss: 0.4926 - acc: 0.7593\n",
            "60000/60000 [==============================] - 2s 26us/step\n",
            "\n",
            "Test accuacy: 77.2717%\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 10s 32us/step - loss: 0.4876 - acc: 0.7629\n",
            "60000/60000 [==============================] - 2s 26us/step\n",
            "\n",
            "Test accuacy: 77.2683%\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 10s 32us/step - loss: 0.4854 - acc: 0.7642\n",
            "60000/60000 [==============================] - 2s 26us/step\n",
            "\n",
            "Test accuacy: 77.3083%\n",
            "Epoch 1/1\n",
            "300000/300000 [==============================] - 10s 32us/step - loss: 0.4837 - acc: 0.7655\n",
            "60000/60000 [==============================] - 1s 25us/step\n",
            "\n",
            "Test accuacy: 77.3217%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDpH6xcJ6_s",
        "colab_type": "text"
      },
      "source": [
        "### Results:\n",
        "\n",
        "1. Minimal modifications\n",
        "    - `74.7633%`\n",
        "    - `76.2417%`\n",
        "    - `76.4933%`\n",
        "    - `76.5517%`\n",
        "    - `76.4916%`\n",
        "    - `76.5200%`\n",
        "2. Added one-hotted `nom_8`\n",
        "    - `73.2983%`\n",
        "    - `76.8950%`\n",
        "    - `77.2717%`\n",
        "    - `77.2683%`\n",
        "    - `77.3083%`\n",
        "    - `77.3217%`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BxQ2Cl57uUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Testing\n",
        "# delete_list = ['data','x_pretest','x_train','y_pretest','y_train','x']\n",
        "# for i,v in enumerate(delete_list):        \n",
        "try:\n",
        "    del data\n",
        "    print(\"Cleared data\")\n",
        "except:\n",
        "    pass\n",
        "    \n",
        "try:\n",
        "    del x\n",
        "    print(\"Cleared x\")\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    del x_pretest,x_train,y_pretest,y_train\n",
        "    print(\"Cleared others\")\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtZCipfF7lki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "#Initialize nom_np\n",
        "data['nom_9'] = data['nom_9'].astype('str')\n",
        "nom_np = (h.transform(data['nom_9'].values)).todense()\n",
        "data = data.drop(columns = drop)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i,w in enumerate(one_hot):\n",
        "\n",
        "   data = pd.get_dummies(data, columns=[w], prefix = [w])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for i,w in enumerate(labelled):\n",
        "\n",
        "    # labels = data[w].astype('category').cat.categories.tolist()\n",
        "\n",
        "    # replace_map_comp = {w: {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
        "\n",
        "    # data.replace(replace_map_comp, inplace=True)\n",
        "\n",
        "    # del labels, replace_map_comp\n",
        "\n",
        "    # print(data[w])\n",
        "\n",
        "\n",
        "for i,w in enumerate(duplicate):\n",
        "    for j in range(duplicatecount):\n",
        "        data = pd.concat([data, data[w]],axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "columns_list2 = data.columns\n",
        "data_ins = [0]*200000\n",
        "for i in range(len(columns_list)):\n",
        "    if columns_list[i] not in columns_list2:\n",
        "        index_name = columns_list[i]\n",
        "        index = i\n",
        "data.insert(index,index_name,data_ins)\n",
        "print(columns_list)\n",
        "print(columns_list2)\n",
        "if(columns_list == data.columns).all():\n",
        "    print(\"equal hdeaders\")\n",
        "x_test = data.to_numpy()\n",
        "try:\n",
        "    del data,NAlist\n",
        "except:\n",
        "    pass\n",
        "print(nom_np.shape,\"NOM_NP_SHAP\")\n",
        "print(x_test.shape)\n",
        "x_test = np.concatenate((x_test,nom_np), axis = 1)\n",
        "print(x_test.shape)\n",
        "\n",
        "try:\n",
        "    del nom_np\n",
        "except:\n",
        "    pass\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "x_test = min_max_scaler.fit_transform(x_test)\n",
        "\n",
        " \n",
        "\n",
        "# print(\"X_testshape\",x_test.shape)\n",
        "\n",
        "y_test = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a64TAeTa7g6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Formatting into csv submittable\n",
        "\n",
        "id = np.arange(start = 300000, stop = 500000)\n",
        "\n",
        "id = np.transpose(id)\n",
        "\n",
        "id = id.reshape(200000,1)\n",
        "\n",
        "y_temp = y_test[:,1].reshape(200000,1)\n",
        "\n",
        "y_pred = np.concatenate((id, y_temp), axis = 1)\n",
        "\n",
        "print(id.shape)\n",
        "\n",
        "print(y_test[:,0].shape)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "presubmission = pd.DataFrame(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "presubmission.iloc[:,0] = presubmission.iloc[:,0].astype(int)\n",
        "\n",
        "presubmission.iloc[:,1] = presubmission.iloc[:,1].astype(float)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "presubmission.to_csv(\"submission.csv\",header = [\"id\",\"target\"],index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}