{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0928 03:30:46.015121  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0928 03:30:46.034086  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0928 03:30:46.106890  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0928 03:30:46.119840  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0928 03:30:46.125839  1464 deprecation.py:506] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0928 03:30:46.498796  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0928 03:30:46.544673  1464 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0928 03:30:46.680310  1464 deprecation.py:323] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.1900 - acc: 0.2599\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "-------- 0 --------\n",
      "Accuracy:  31.970000038146974\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8475 - acc: 0.3381\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 1 --------\n",
      "Accuracy:  34.840000009536745\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.7398 - acc: 0.3740\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 2 --------\n",
      "Accuracy:  38.39999998569488\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6659 - acc: 0.4028\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 3 --------\n",
      "Accuracy:  36.63000002384186\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6346 - acc: 0.4111\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 4 --------\n",
      "Accuracy:  37.56999996185303\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6130 - acc: 0.4236\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 5 --------\n",
      "Accuracy:  42.27999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.5965 - acc: 0.4263\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 6 --------\n",
      "Accuracy:  42.63000001907349\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5731 - acc: 0.4329\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "-------- 7 --------\n",
      "Accuracy:  42.78000001430512\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5530 - acc: 0.4426\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 8 --------\n",
      "Accuracy:  43.70999999523163\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5471 - acc: 0.4448\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 9 --------\n",
      "Accuracy:  42.14000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5460 - acc: 0.4429\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 10 --------\n",
      "Accuracy:  44.74000000476837\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5415 - acc: 0.4455\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 11 --------\n",
      "Accuracy:  46.46999998092652\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5236 - acc: 0.4525\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 12 --------\n",
      "Accuracy:  47.080000033378596\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5100 - acc: 0.4587\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 13 --------\n",
      "Accuracy:  45.3800000333786\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4973 - acc: 0.4618\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 14 --------\n",
      "Accuracy:  48.30999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4911 - acc: 0.4649\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 15 --------\n",
      "Accuracy:  48.75999997615814\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4832 - acc: 0.4674\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 16 --------\n",
      "Accuracy:  49.88999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4750 - acc: 0.4710\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 17 --------\n",
      "Accuracy:  47.75000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4658 - acc: 0.4723\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 18 --------\n",
      "Accuracy:  47.690000009536746\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4525 - acc: 0.4761\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 19 --------\n",
      "Accuracy:  48.22000000953675\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4409 - acc: 0.4835\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 20 --------\n",
      "Accuracy:  48.300000038146976\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.4412 - acc: 0.4818\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 21 --------\n",
      "Accuracy:  48.45999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4314 - acc: 0.4848\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 22 --------\n",
      "Accuracy:  49.17999997138977\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4292 - acc: 0.4848\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 23 --------\n",
      "Accuracy:  49.03999998092651\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4229 - acc: 0.4895\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 24 --------\n",
      "Accuracy:  49.03999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4092 - acc: 0.4896\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 25 --------\n",
      "Accuracy:  50.94000003814697\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4086 - acc: 0.4943\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 26 --------\n",
      "Accuracy:  50.879999966621405\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4008 - acc: 0.4968\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 27 --------\n",
      "Accuracy:  47.400000014305114\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4011 - acc: 0.4968\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 28 --------\n",
      "Accuracy:  50.59999997138978\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4079 - acc: 0.4928\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 29 --------\n",
      "Accuracy:  49.51000002384186\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3921 - acc: 0.4980\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "-------- 30 --------\n",
      "Accuracy:  49.79999999523163\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3880 - acc: 0.5022\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 31 --------\n",
      "Accuracy:  50.21999997615815\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3838 - acc: 0.5017\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 32 --------\n",
      "Accuracy:  47.40000002384186\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3805 - acc: 0.5011\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 33 --------\n",
      "Accuracy:  49.35000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3823 - acc: 0.5028\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 34 --------\n",
      "Accuracy:  49.6599999666214\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3655 - acc: 0.5082\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 35 --------\n",
      "Accuracy:  51.85000000476837\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3507 - acc: 0.5145\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 36 --------\n",
      "Accuracy:  50.9\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3581 - acc: 0.5142\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 37 --------\n",
      "Accuracy:  50.90000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3448 - acc: 0.5177\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 38 --------\n",
      "Accuracy:  49.5099999666214\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.3411 - acc: 0.5175\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 39 --------\n",
      "Accuracy:  50.82999999046326\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3398 - acc: 0.5158\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 40 --------\n",
      "Accuracy:  50.089999980926514\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.3394 - acc: 0.5159\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 41 --------\n",
      "Accuracy:  51.340000028610234\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3313 - acc: 0.5210\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 42 --------\n",
      "Accuracy:  51.37999997615814\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3214 - acc: 0.5230\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 43 --------\n",
      "Accuracy:  51.639999966621396\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3243 - acc: 0.5230\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 44 --------\n",
      "Accuracy:  51.28999998569489\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3229 - acc: 0.5237\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 45 --------\n",
      "Accuracy:  49.72999997615814\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3082 - acc: 0.5303\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 46 --------\n",
      "Accuracy:  52.50000003814698\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      " Final Accuracy:  52.50000003814698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Deprecated. Replaced with keras.datasets\n",
    "#For CS231N data loading\n",
    "import os\n",
    "import platform\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense,Activation,BatchNormalization,Dropout\n",
    "\n",
    "from keras.optimizers import adam\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#print('Training data shape: ', X_train.shape)\n",
    "#print('Training labels shape: ', y_train.shape)\n",
    "#print('Test data shape: ', X_test.shape)\n",
    "#print('Test labels shape: ', y_test.shape)   \n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "y_train = y_train.astype('float')\n",
    "y_test = y_test.astype('float')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train.reshape(50000,3072)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "X_test = X_test.reshape(10000,3072)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropout = 0.3\n",
    "activation = 'relu'\n",
    "model = Sequential()\n",
    "\n",
    "#Layer1\n",
    "model.add(Dense(512,input_dim = 3072))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer2\n",
    "model.add(Dense(512,input_dim = 512))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#layer3\n",
    "model.add(Dense(512,input_dim = 512))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#DenseOutput10\n",
    "model.add(Dense(10,input_dim = 512))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.summary()\n",
    "epochs_num = 100\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "maxscore = -1\n",
    "checker = 0\n",
    "for i in range(epochs_num):\n",
    "    model.fit(X_train, y_train, epochs = 1 , batch_size = 512)\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, batch_size = 512)\n",
    "    print(\"--------\",i,\"--------\")\n",
    "    print(\"Accuracy: \",(100.0 * score[1]))\n",
    "    if(score[1] > 0.52):\n",
    "        break\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size = 512)\n",
    "print(\" Final Accuracy: \",(100.0 * score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I just played around and decided on 50 epochs after that the increase is relatively small\n",
    "#It does reach a sizeable portion of it's final accureacy when using 20ish epochs\n",
    "#When run for 100 epochs overfitting begins to set in at around 40 epochs.\n",
    "#Therefore perform a break at around 40 epochs if accuracy is greater than 52 (consistently one of the greatest accuracies afterwards)\n",
    "#It just overfits anyway so 512 is more than sufficient for the hidden layers\n",
    "#Adam is generally the best performing even for the first project (drivendata.org competition)\n",
    "#Relu is also generally the best. The two I had the most success with for drivendata, admittedly more of my playing around was for that project)\n",
    "#was with ReLU and tanh\n",
    "#BatchNormalization seems to reduce the epochs it needs to reach 52\n",
    "#Admittedly I should not be validating on my test set.\n",
    "#This break setup of mine is better done if i had another validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
