{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0920 19:03:39.994949 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0920 19:03:40.010875 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0920 19:03:40.012869 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0920 19:03:40.031819 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0920 19:03:40.040796 14340 deprecation.py:506] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0920 19:03:40.395877 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0920 19:03:40.417834 14340 deprecation_wrapper.py:119] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0920 19:03:40.508579 14340 deprecation.py:323] From c:\\users\\marcus\\anaconda3\\envs\\coe197z\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.3924 - acc: 0.2016\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "-------- 0 --------\n",
      "Accuracy:  25.710000007152555\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.0138 - acc: 0.2734\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 1 --------\n",
      "Accuracy:  26.039999997615816\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8827 - acc: 0.3157\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 2 --------\n",
      "Accuracy:  30.34000001192093\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8141 - acc: 0.3397\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 3 --------\n",
      "Accuracy:  33.07000001430511\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7805 - acc: 0.3564\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 4 --------\n",
      "Accuracy:  38.47\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7588 - acc: 0.3642\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 5 --------\n",
      "Accuracy:  34.9900000333786\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7457 - acc: 0.3722\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 6 --------\n",
      "Accuracy:  38.6999999666214\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7362 - acc: 0.3755: 0s - loss: 1.7361 - acc: 0.37\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "-------- 7 --------\n",
      "Accuracy:  34.16999999046325\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7344 - acc: 0.3775\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "-------- 8 --------\n",
      "Accuracy:  39.69000003814697\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7191 - acc: 0.3795\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 9 --------\n",
      "Accuracy:  36.360000014305115\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7208 - acc: 0.3803\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "-------- 10 --------\n",
      "Accuracy:  40.29000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7174 - acc: 0.3770\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 11 --------\n",
      "Accuracy:  41.630000038146974\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7169 - acc: 0.3797\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "-------- 12 --------\n",
      "Accuracy:  43.770000038146975\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 62us/step - loss: 1.7021 - acc: 0.3869\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "-------- 13 --------\n",
      "Accuracy:  45.1100000333786\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6962 - acc: 0.3887\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "-------- 14 --------\n",
      "Accuracy:  43.50999998092651\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6805 - acc: 0.3915\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 15 --------\n",
      "Accuracy:  44.25000001907349\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6881 - acc: 0.3902\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 16 --------\n",
      "Accuracy:  44.040000033378604\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6769 - acc: 0.3950\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 17 --------\n",
      "Accuracy:  44.68999998569488\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6655 - acc: 0.3995\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "-------- 18 --------\n",
      "Accuracy:  43.33000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6572 - acc: 0.3996\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 19 --------\n",
      "Accuracy:  44.959999985694886\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6520 - acc: 0.4040\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 20 --------\n",
      "Accuracy:  44.36999996185303\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6452 - acc: 0.4075\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 21 --------\n",
      "Accuracy:  44.66000001430511\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.6375 - acc: 0.4069\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 22 --------\n",
      "Accuracy:  44.2000000333786\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6405 - acc: 0.4108\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "-------- 23 --------\n",
      "Accuracy:  46.30999996185302\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6292 - acc: 0.4120\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "-------- 24 --------\n",
      "Accuracy:  45.4900000333786\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.6231 - acc: 0.4169: 0s - loss: 1.6242 - acc: \n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "-------- 25 --------\n",
      "Accuracy:  46.02999999046325\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6151 - acc: 0.4142\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 26 --------\n",
      "Accuracy:  46.1699999666214\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6168 - acc: 0.4183\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 27 --------\n",
      "Accuracy:  44.330000000000005\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6128 - acc: 0.4185\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 28 --------\n",
      "Accuracy:  45.84999997615814\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6100 - acc: 0.4184\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 29 --------\n",
      "Accuracy:  45.37999999523163\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6068 - acc: 0.4216\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 30 --------\n",
      "Accuracy:  46.10000002384186\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6039 - acc: 0.4218\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 31 --------\n",
      "Accuracy:  47.149999971389775\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6014 - acc: 0.4210\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 32 --------\n",
      "Accuracy:  46.37999998569489\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5925 - acc: 0.4261\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 33 --------\n",
      "Accuracy:  47.38\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5981 - acc: 0.4229\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 34 --------\n",
      "Accuracy:  46.750000004768374\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5889 - acc: 0.4224\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 35 --------\n",
      "Accuracy:  46.36999997138977\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5898 - acc: 0.4247\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "-------- 36 --------\n",
      "Accuracy:  46.57000002861023\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5815 - acc: 0.4276\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 37 --------\n",
      "Accuracy:  45.779999966621396\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5934 - acc: 0.4241\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "-------- 38 --------\n",
      "Accuracy:  45.75000002384186\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5898 - acc: 0.4263\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 39 --------\n",
      "Accuracy:  44.57000001907348\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5880 - acc: 0.4250\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 40 --------\n",
      "Accuracy:  44.61999998569489\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5917 - acc: 0.4226\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 41 --------\n",
      "Accuracy:  45.71\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5841 - acc: 0.4293\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 42 --------\n",
      "Accuracy:  46.210000014305116\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5797 - acc: 0.4272: 2\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "-------- 43 --------\n",
      "Accuracy:  44.939999971389774\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5815 - acc: 0.4287\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 44 --------\n",
      "Accuracy:  45.57999998092651\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5781 - acc: 0.4281\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 45 --------\n",
      "Accuracy:  46.14999996185303\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5706 - acc: 0.4322\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 46 --------\n",
      "Accuracy:  46.3399999666214\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5642 - acc: 0.4352\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "-------- 47 --------\n",
      "Accuracy:  45.649999966621394\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5677 - acc: 0.4356\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 48 --------\n",
      "Accuracy:  47.450000009536744\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5620 - acc: 0.4386\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "-------- 49 --------\n",
      "Accuracy:  46.629999990463254\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      " Final Accuracy:  46.629999990463254\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Deprecated. Replaced with keras.datasets\n",
    "#For CS231N data loading\n",
    "import os\n",
    "import platform\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense,Activation,BatchNormalization,Dropout\n",
    "\n",
    "from keras.optimizers import adam\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#print('Training data shape: ', X_train.shape)\n",
    "#print('Training labels shape: ', y_train.shape)\n",
    "#print('Test data shape: ', X_test.shape)\n",
    "#print('Test labels shape: ', y_test.shape)   \n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "y_train = y_train.astype('float')\n",
    "y_test = y_test.astype('float')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train.reshape(50000,3072)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "X_test = X_test.reshape(10000,3072)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropout = 0.5\n",
    "activation = 'relu'\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(512,input_dim = 3072))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(512,input_dim = 512))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(512,input_dim = 512))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Activation(activation))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(10,input_dim = 512))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.summary()\n",
    "epochs_num = 50\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "maxscore = -1\n",
    "checker = 0\n",
    "for i in range(epochs_num):\n",
    "    model.fit(X_train, y_train, epochs = 1 , batch_size = 512)\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, batch_size = 512)\n",
    "    print(\"--------\",i,\"--------\")\n",
    "    print(\"Accuracy: \",(100.0 * score[1]))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size = 512)\n",
    "print(\" Final Accuracy: \",(100.0 * score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I just played around and decided on 50 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
